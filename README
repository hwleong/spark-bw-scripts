Quick Start

The following example assume 1 master, 1 slave and 1 submit hosts (total 18 compute nodes). 

1. Submit the following job. 

hwleong@jyc1:~> qsub -I -l nodes=18:ppn=32,gres=shifter16,walltime=02:00:00 -v UDI=lgerhardt/spark-2.1.1:v1

2. Load "spark-2.1.1" module. 

hwleong@nid00010:~> module load spark-2.1.1

3. Switch to SHIFTER compute environment. 

hwleong@nid00010:~> export CRAY_ROOTFS=SHIFTER

4. Start Spark master. 

hwleong@nid00010:~> alps-start-master.sh

5. Start Spark slaves. 

hwleong@nid00010:~> alps-start-slaves.sh

6. Submit a Spark example job. 

hwleong@nid00010:~> aprun -n 1 -b -- "${SPARK_HOME}/bin/run-example" --master spark://$SPARK_MASTER_HOST:7077 SparkPi 1000 2>/dev/null

